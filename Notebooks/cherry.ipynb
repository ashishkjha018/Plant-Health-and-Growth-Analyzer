{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z8DSZ7LIBUcA"
      },
      "outputs": [],
      "source": [
        "!unzip \"drive/MyDrive/cherry.zip\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Input, Lambda, Dense, Flatten"
      ],
      "metadata": {
        "id": "ZVtqC5gTB05K"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 32\n",
        "Channels = 3\n",
        "EPOCHS = 25\n",
        "INPUT_SHAPE = (IMG_SIZE , IMG_SIZE , Channels)"
      ],
      "metadata": {
        "id": "VjgMzXyDB5bx"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    \"Cherry\",\n",
        "    shuffle = True,\n",
        "    image_size = (IMG_SIZE , IMG_SIZE),\n",
        "    batch_size = BATCH_SIZE\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3-8R7fLB7Il",
        "outputId": "4eed533b-0bbf-49a7-e648-64c38350f799"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3881 files belonging to 3 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = dataset.class_names\n",
        "class_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-um-HfCB-J5",
        "outputId": "36c590cd-cdfa-49bf-c9fe-75f3abb1ec10"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Grape___Esca_(Black_Measles)',\n",
              " 'Grape___Leaf_blight_(Isariopsis_Leaf_Spot)',\n",
              " 'Grape___healthy']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dataset_partitions_tf(ds , train_split = 0.8,val_split=0.1,test_split=0.1,shuffle=True ,shuffle_size=1000):\n",
        "\n",
        "    ds_size = len(ds)\n",
        "    if shuffle:\n",
        "        ds = ds.shuffle(shuffle_size,seed=12)\n",
        "    train_size = int(train_split * ds_size)\n",
        "    val_size = int(val_split * ds_size)\n",
        "\n",
        "    train_ds = ds.take(train_size)\n",
        "    val_ds = ds.skip(train_size).take(val_size)\n",
        "    test_ds = ds.skip(train_size).skip(val_size)\n",
        "\n",
        "\n",
        "    return train_ds , val_ds , test_ds"
      ],
      "metadata": {
        "id": "p1W33vR1CBlz"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds , val_ds , test_ds = get_dataset_partitions_tf(dataset)"
      ],
      "metadata": {
        "id": "W818u_H1CDoG"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "val_ds = val_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "test_ds = test_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\n"
      ],
      "metadata": {
        "id": "jsjzAvdRCGQd"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resize_and_rescale = tf.keras.Sequential([\n",
        "    layers.experimental.preprocessing.Resizing(IMG_SIZE,IMG_SIZE),\n",
        "    layers.experimental.preprocessing.Rescaling(1.0/255)\n",
        "])"
      ],
      "metadata": {
        "id": "5HO1GHNtCHzb"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_agumentation = tf.keras.Sequential([\n",
        "    layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n",
        "    layers.experimental.preprocessing.RandomRotation(0.2),\n",
        "])"
      ],
      "metadata": {
        "id": "WAo1oDRKCJuJ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vgg = tf.keras.applications.VGG16(input_shape=INPUT_SHAPE, weights='imagenet', include_top=False)"
      ],
      "metadata": {
        "id": "1lgf2uKsCL_5"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# don't train existing weights\n",
        "for layer in vgg.layers:\n",
        "    layer.trainable = False"
      ],
      "metadata": {
        "id": "FOVamyacCQbL"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_classes = 2\n",
        "model = tf.keras.Sequential()\n",
        "model.add(resize_and_rescale)\n",
        "model.add(data_agumentation)\n",
        "model.add(vgg)\n",
        "model.add(Flatten())\n",
        "model.add(Dense(n_classes,activation='softmax'))\n",
        "model.build(input_shape=(None, IMG_SIZE, IMG_SIZE, Channels))"
      ],
      "metadata": {
        "id": "imf1HfqECTwM"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P4fPkX0fCa3z",
        "outputId": "9b81d100-7cc4-4dd4-953f-18d83b4d88db"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " sequential (Sequential)     (None, 224, 224, 3)       0         \n",
            "                                                                 \n",
            " sequential_1 (Sequential)   (None, 224, 224, 3)       0         \n",
            "                                                                 \n",
            " vgg16 (Functional)          (None, 7, 7, 512)         14714688  \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 25088)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 50178     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14764866 (56.32 MB)\n",
            "Trainable params: 50178 (196.01 KB)\n",
            "Non-trainable params: 14714688 (56.13 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer = 'adam',\n",
        "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "QIRnTlPsCdOR"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_ds,\n",
        "    epochs = 25,\n",
        "    batch_size = BATCH_SIZE,\n",
        "    verbose = 1,\n",
        "    validation_data = val_ds\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WicnGZ-4CgJH",
        "outputId": "d9473826-f575-447a-bbb8-eccdeaa04096"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "176/176 [==============================] - 57s 214ms/step - loss: 0.0624 - accuracy: 0.9788 - val_loss: 0.0093 - val_accuracy: 0.9972\n",
            "Epoch 2/25\n",
            "176/176 [==============================] - 29s 166ms/step - loss: 0.0069 - accuracy: 0.9991 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
            "Epoch 3/25\n",
            "176/176 [==============================] - 28s 158ms/step - loss: 0.0037 - accuracy: 0.9995 - val_loss: 0.0034 - val_accuracy: 0.9986\n",
            "Epoch 4/25\n",
            "176/176 [==============================] - 30s 169ms/step - loss: 0.0021 - accuracy: 0.9998 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 5/25\n",
            "176/176 [==============================] - 31s 174ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 8.0786e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/25\n",
            "176/176 [==============================] - 28s 159ms/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 8.5718e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/25\n",
            "176/176 [==============================] - 28s 162ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 7.7946e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/25\n",
            "176/176 [==============================] - 30s 172ms/step - loss: 8.9000e-04 - accuracy: 0.9998 - val_loss: 4.4292e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/25\n",
            "176/176 [==============================] - 28s 158ms/step - loss: 5.2120e-04 - accuracy: 1.0000 - val_loss: 3.7074e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/25\n",
            "176/176 [==============================] - 29s 165ms/step - loss: 5.5967e-04 - accuracy: 1.0000 - val_loss: 3.3012e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/25\n",
            "176/176 [==============================] - 30s 169ms/step - loss: 7.6473e-04 - accuracy: 1.0000 - val_loss: 3.1876e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/25\n",
            "176/176 [==============================] - 30s 170ms/step - loss: 2.4546e-04 - accuracy: 1.0000 - val_loss: 5.9040e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/25\n",
            "176/176 [==============================] - 29s 162ms/step - loss: 2.9764e-04 - accuracy: 1.0000 - val_loss: 3.9491e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/25\n",
            "176/176 [==============================] - 28s 160ms/step - loss: 1.6090e-04 - accuracy: 1.0000 - val_loss: 2.3781e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/25\n",
            "176/176 [==============================] - 28s 158ms/step - loss: 7.2373e-04 - accuracy: 0.9996 - val_loss: 6.7559e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/25\n",
            "176/176 [==============================] - 28s 159ms/step - loss: 1.5626e-04 - accuracy: 1.0000 - val_loss: 1.6975e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/25\n",
            "176/176 [==============================] - 28s 159ms/step - loss: 1.8914e-04 - accuracy: 1.0000 - val_loss: 1.2985e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/25\n",
            "176/176 [==============================] - 28s 159ms/step - loss: 1.7963e-04 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 19/25\n",
            "176/176 [==============================] - 28s 161ms/step - loss: 1.1553e-04 - accuracy: 1.0000 - val_loss: 3.8150e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/25\n",
            "176/176 [==============================] - 30s 171ms/step - loss: 3.5866e-04 - accuracy: 1.0000 - val_loss: 1.3714e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/25\n",
            "176/176 [==============================] - 28s 161ms/step - loss: 8.5863e-05 - accuracy: 1.0000 - val_loss: 2.5925e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/25\n",
            "176/176 [==============================] - 28s 159ms/step - loss: 7.5419e-05 - accuracy: 1.0000 - val_loss: 1.9621e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/25\n",
            "176/176 [==============================] - 28s 159ms/step - loss: 5.4502e-05 - accuracy: 1.0000 - val_loss: 1.6856e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/25\n",
            "176/176 [==============================] - 28s 159ms/step - loss: 5.0526e-05 - accuracy: 1.0000 - val_loss: 1.2694e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/25\n",
            "176/176 [==============================] - 28s 159ms/step - loss: 0.0060 - accuracy: 0.9977 - val_loss: 0.0109 - val_accuracy: 0.9943\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"cherry_vgg16.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iMmtOPwPMD1I",
        "outputId": "de4d82f8-0cb5-4457-a209-ab64b8746426"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_acc = history.history['accuracy']\n",
        "training_loss = history.history['loss']\n",
        "val_acc = history.history['val_accuracy']\n",
        "val_loss = history.history['val_loss']"
      ],
      "metadata": {
        "id": "T_bvkBcuCi8S"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores = model.evaluate(test_ds)"
      ],
      "metadata": {
        "id": "6zNf3fl7GWN3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "bxj7ww5fGYQs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 8))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(range(len(training_acc)), training_acc, label='Accuracy of Training')\n",
        "plt.plot(range(len(val_acc)), val_acc, label='Val accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title(\"Accuracy of Training and Validation\")\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(range(len(training_loss)), training_loss, label='Accuracy of Loss')\n",
        "plt.plot(range(len(val_loss)), val_loss, label='Val loss')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title(\"Loss of Training and Validation\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HkgZx0qYRcFc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "vr7j4fevReCz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for images_batch , labels_batch in test_ds.take(1):\n",
        "    first_image = images_batch[0].numpy().astype('uint8')\n",
        "    first_label = labels_batch[0].numpy()\n",
        "\n",
        "    print('first image to predict')\n",
        "    plt.imshow(first_image)\n",
        "\n",
        "    print(\"first image's actual label:\",class_names[first_label])\n",
        "\n",
        "    batch_prediction = model.predict(images_batch)\n",
        "    print(\"predicted label:\",class_names[np.argmax(batch_prediction[0])])"
      ],
      "metadata": {
        "id": "aULodfYRRjsw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model , img):\n",
        "    img_array = tf.keras.preprocessing.image.img_to_array(images[i].numpy())\n",
        "    img_array = tf.expand_dims(img_array,0)\n",
        "\n",
        "    predictions = model.predict(img_array)\n",
        "\n",
        "    predicted_class = class_names[np.argmax(predictions[0])]\n",
        "    confidence = round(100*(np.max(predictions[0])),2)\n",
        "    return predicted_class , confidence"
      ],
      "metadata": {
        "id": "2XbpjbJeRksZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,15))\n",
        "for images, labels in test_ds.take(1):\n",
        "    for i in range(9):\n",
        "        ax = plt.subplot(3,3,i+1)\n",
        "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "\n",
        "        predicted_class , confidence = predict(model , images[i].numpy())\n",
        "        actual_class = class_names[labels[i]]\n",
        "\n",
        "        plt.title(f\"actual:{actual_class},\\n predicted:{predicted_class}.\\n confidence:{confidence}%\")\n",
        "        plt.axis('off')"
      ],
      "metadata": {
        "id": "jRUTLD3WRpBg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Jigj-rIoRqcQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}